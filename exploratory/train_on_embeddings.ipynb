{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a jupyter notebook, running using the `pixi` environment we created to manage our dependencies. Note that you may need to change your python interpreter (top right corner) to:\n",
    "`.pixi/envs/default/bin/python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from opensoundscape.ml import bioacoustics_model_zoo as bmz\n",
    "from opensoundscape.ml.shallow_classifier import quick_fit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"/workspaces/non-avian-ml-toy/data/audio\"\n",
    "species = \"bullfrog\"\n",
    "datatype = \"data\"\n",
    "\n",
    "files = glob.glob(os.path.join(datapath, species, datatype, \"**/*.wav\"), recursive=True)\n",
    "labels = pd.DataFrame({\"file\": files, \"present\": [\"pos\" in f.lower() for f in files]})\n",
    "labels['file'] = labels['file'].astype(str)\n",
    "labels.set_index(\"file\", inplace=True)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "print(labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train, labels_val = sklearn.model_selection.train_test_split(labels[['present']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a model from the model zoo\n",
    "model = bmz.load('BirdNET') #or bmz.load('Perch')\n",
    "\n",
    "emb_train = model.embed(labels_train, return_dfs=False, batch_size=128, num_workers=0)\n",
    "emb_val = model.embed(labels_val, return_dfs=False, batch_size=128, num_workers=0)\n",
    "\n",
    "classes = ['A']\n",
    "birdnet.change_classes(classes) \n",
    "\n",
    "# fit the classification head with embeddings and labels\n",
    "birdnet.network.fit(emb_train, labels_train.values, emb_val, labels_val.values)\n",
    "\n",
    "# make predictions by passing the embeddings through the classifier\n",
    "preds = birdnet.network(torch.tensor(emb_val)).detach()\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score(labels_val.values,preds,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.detach().numpy()\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
