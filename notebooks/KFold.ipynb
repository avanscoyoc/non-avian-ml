{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec4415fa-f8c4-48e2-8ea5-f3a6223ef716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from opensoundscape.ml import bioacoustics_model_zoo as bmz\n",
    "from opensoundscape.ml.shallow_classifier import quick_fit \n",
    "\n",
    "from scipy.special import softmax\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51df943c-0d9f-4f96-a814-fd4b2e8a18f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bullfrog</th>\n",
       "      <th>coyote</th>\n",
       "      <th>noise</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>files</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bullfrog, coyote, noise]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = \"/workspaces/non-avian-ml-toy/data/audio\"\n",
    "species_list = [\"bullfrog\", \"coyote\", 'noise']\n",
    "\n",
    "datatype = \"data\"\n",
    "\n",
    "# audio\n",
    "# - bullfrog\n",
    "#   - data\n",
    "#       - pos\n",
    "#       - neg\n",
    "# - coyote\n",
    "#   - data\n",
    "#      - pos \n",
    "# '/workspaces/non-avian-ml-toy/data/audio/bullfrog/data/neg/bullfrog-neg-t-11113588_9.wav' # Following this format\n",
    "# Creating a dataframe for each animal species with file paths and labels\n",
    "\n",
    "df_each_species = defaultdict(list) # Create a dictionary to hold dataframes for each species\n",
    "# df_each_species = animal_species: df\n",
    "# Combine all species dataframes into one\n",
    "\n",
    "# Note Can also use OneHotEncoder in Sckit-learn\n",
    "all_species = pd.DataFrame()\n",
    "for species in species_list:\n",
    "    # Files Paths\n",
    "    pos_files = glob.glob(os.path.join(datapath, species, datatype, \"pos\", \"*.wav\")) # List of Each species pos files\n",
    "    neg_files = glob.glob(os.path.join(datapath, species, datatype, \"neg\", \"*.wav\")) # List of Each species pos files\n",
    "    all_files = pos_files + neg_files # Combine all file paths\n",
    "\n",
    "    # Encoding\n",
    "    pos_files_init = [1] * len(pos_files) # List of 1s for each positive file\n",
    "    neg_files_init = [0] * len(neg_files) # List of 0s for each negative file\n",
    "    encoding_pos_files = pos_files_init + neg_files_init\n",
    "    encoding_neg_files = neg_files_init + pos_files_init\n",
    "\n",
    "    pd_each_species = pd.DataFrame({'files': all_files, species: encoding_pos_files, 'noise': encoding_neg_files})\n",
    "    df_each_species[species] = pd_each_species\n",
    "\n",
    "for species in species_list:\n",
    "    all_species = pd.concat([all_species, df_each_species[species]], axis=0)\n",
    "\n",
    "# Fill NaN values with 0, set index, convert to int\n",
    "all_species.fillna(0, inplace=True)  # Replace NaN values with 0\n",
    "all_species.set_index(\"files\", inplace=True)  # Set 'files' as the index\n",
    "all_species = all_species.astype(int)  # Convert to int\n",
    "\n",
    "# Optionally putting other in the last Row\n",
    "if True:\n",
    "    other_col = all_species.pop(\"noise\")\n",
    "    all_species.insert(len(all_species.columns), \"noise\", other_col)\n",
    "idx_to_all_species = {i: col for i, col in enumerate(all_species.columns)}\n",
    "\n",
    "df_each_species\n",
    "all_species\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e5acbf-1f37-4519-8bba-241d5b2f4945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/kitzeslab_bioacoustics-model-zoo_main\n",
      "2025-04-08 16:29:30.335434: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-08 16:29:31.020447: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-08 16:29:31.020495: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-08 16:29:31.023607: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-08 16:29:31.366862: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-08 16:29:32.795159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File BirdNET_GLOBAL_6K_V2.4_Labels_af.txt already exists; skipping download.\n",
      "downloading model from URL...\n",
      "File BirdNET_GLOBAL_6K_V2.4_Model_FP16.tflite already exists; skipping download.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/non-avian-ml-toy/.pixi/envs/default/lib/python3.10/site-packages/opensoundscape/ml/cnn.py:621: UserWarning: \n",
      "                    This architecture is not listed in opensoundscape.ml.cnn_architectures.ARCH_DICT.\n",
      "                    It will not be available for loading after saving the model with .save() (unless using pickle=True). \n",
      "                    To make it re-loadable, define a function that generates the architecture from arguments: (n_classes, n_channels) \n",
      "                    then use opensoundscape.ml.cnn_architectures.register_architecture() to register the generating function.\n",
      "\n",
      "                    The function can also set the returned object's .constructor_name to the registered string key in ARCH_DICT\n",
      "                    to avoid this warning and ensure it is reloaded correctly by opensoundscape.ml.load_model().\n",
      "\n",
      "                    See opensoundscape.ml.cnn_architectures module for examples of constructor functions\n",
      "                    \n",
      "  warnings.warn(\n",
      "/workspaces/non-avian-ml-toy/.pixi/envs/default/lib/python3.10/site-packages/opensoundscape/ml/cnn.py:645: UserWarning: Failed to detect expected # input channels of this architecture.Make sure your architecture expects the number of channels equal to `channels` argument 1). Pytorch architectures generally expect 3 channels by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#model = bmz.BirdNET()\n",
    "\n",
    "model = torch.hub.load('kitzeslab/bioacoustics-model-zoo', \"BirdNET\", trust_repo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70dde2d1-f996-4483-89bf-0eef24c76039",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m ROC_AUC_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Perform Stratified K-Fold\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold_idx, (train_idx, test_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mskf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m):  \n\u001b[1;32m     16\u001b[0m     train_files, test_files \u001b[38;5;241m=\u001b[39m file_paths\u001b[38;5;241m.\u001b[39miloc[train_idx]\u001b[38;5;241m.\u001b[39mtolist(), file_paths\u001b[38;5;241m.\u001b[39miloc[test_idx]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     17\u001b[0m     labels_train, labels_val \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39miloc[train_idx], labels\u001b[38;5;241m.\u001b[39miloc[test_idx]\n",
      "File \u001b[0;32m/workspaces/non-avian-ml-toy/.pixi/envs/default/lib/python3.10/site-packages/sklearn/model_selection/_split.py:881\u001b[0m, in \u001b[0;36mStratifiedKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m groups \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    878\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe groups parameter is ignored by \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    880\u001b[0m     )\n\u001b[0;32m--> 881\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n",
      "File \u001b[0;32m/workspaces/non-avian-ml-toy/.pixi/envs/default/lib/python3.10/site-packages/sklearn/utils/validation.py:1130\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1131\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1132\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1133\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m   1134\u001b[0m         )\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1137\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "# Use maximum CPUs for your device\n",
    "num_workers = os.cpu_count() * 3 // 4  \n",
    "\n",
    "curr_df = df_each_species['coyote']\n",
    "\n",
    "file_paths = curr_df['files'] \n",
    "labels = curr_df['coyote']  \n",
    "\n",
    "fold_num = 5\n",
    "skf = StratifiedKFold(n_splits=fold_num, shuffle=True, random_state=8)\n",
    "\n",
    "ROC_AUC_scores = []\n",
    "\n",
    "# Perform Stratified K-Fold\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(skf.split(file_paths, labels)):  \n",
    "    train_files, test_files = file_paths.iloc[train_idx].tolist(), file_paths.iloc[test_idx].tolist()\n",
    "    labels_train, labels_val = labels.iloc[train_idx], labels.iloc[test_idx]\n",
    "    print(train_files, test_files)\n",
    "\n",
    "    # Reshape labels to match the model output shape\n",
    "    labels_train = labels_train.to_numpy().reshape(-1, 1)  \n",
    "    labels_val = labels_val.to_numpy().reshape(-1, 1)  \n",
    "\n",
    "    # Generate embeddings for training and validation sets\n",
    "    emb_train = model.embed(train_files, return_dfs=False, batch_size=4, num_workers=num_workers)\n",
    "    emb_val = model.embed(test_files, return_dfs=False, batch_size=4, num_workers=num_workers)\n",
    "\n",
    "    # Define class for training (only \"bullfrog\")\n",
    "    classes = ['bullfrog']\n",
    "    model.change_classes(classes)\n",
    "\n",
    "    # Fit the classification head with embeddings and labels\n",
    "    model.network.fit(emb_train, labels_train, emb_val, labels_val)\n",
    "\n",
    "    # Make predictions by passing the embeddings through the classifier\n",
    "    # https://github.com/kitzeslab/bioacoustics-model-zoo/blob/main/bioacoustics_model_zoo/tensorflow_wrapper.py#L19\n",
    "\n",
    "\n",
    "    # NEED TO CHANGE THIS I don't think this is correct\n",
    "    preds = model.network(torch.tensor(emb_val)).detach() # Return raws logits of predictions not the preds\n",
    "    \n",
    "    curr_score = roc_auc_score(labels_val, preds, average=None) \n",
    "    ROC_AUC_scores.append(curr_score)\n",
    "\n",
    "    # Plot histogram of predictions\n",
    "    preds = preds.detach().numpy()\n",
    "    # plt.hist(preds[labels_val == 1], bins=20, alpha=0.5, label='Bullfrog Present')\n",
    "    # plt.hist(preds[labels_val == 0], bins=20, alpha=0.5, label='Bullfrog Absent')\n",
    "    # plt.title(f\"Fold {fold_idx + 1}\")\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    # Print Fold Information\n",
    "    # print('---------------------------')\n",
    "    # print(f\"Current Fold: {fold_idx + 1}\")\n",
    "    # print(f\"ROC AUC Score: {curr_score}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f88185-a3fe-4302-ad69-12e6c19dca02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: ROC AUC Score = 1.0\n",
      "Fold 2: ROC AUC Score = 1.0\n",
      "Fold 3: ROC AUC Score = 0.7777777777777779\n",
      "Fold 4: ROC AUC Score = 1.0\n",
      "Fold 5: ROC AUC Score = 1.0\n",
      "Average Across All folds: 0.9555555555555555\n"
     ]
    }
   ],
   "source": [
    "# Average ROC AUC score across all folds\n",
    "average_roc_auc = np.mean(ROC_AUC_scores)\n",
    "for i, score in enumerate(ROC_AUC_scores):\n",
    "    print(f\"Fold {i + 1}: ROC AUC Score = {score}\")\n",
    "print(f'Average Across All folds: {average_roc_auc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
